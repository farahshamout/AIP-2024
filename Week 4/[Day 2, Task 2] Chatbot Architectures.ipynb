{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xgZwBLWR4y1"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/farahshamout/AIP-2024/blob/main/Week%204/%5BDay%202%2C%20Task%202%5D%20Chatbot%20Architectures.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLgu7dM6R4y1"
      },
      "source": [
        "# Retrieval Augmented Generation and Chatbot Architectures\n",
        "\n",
        "In this notebook we will work through what it takes to build a chatbot from the most basic version, all the way through to a more complicated chatbot that uses a conversational agent with tools as well as guardrails."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rhH_kCndR4y1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-...\"  #put the API key in here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "yozbzojXR4y2",
        "outputId": "866c0b7b-5ab8-433d-d54a-ae3e43c3da7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.41.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.112.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.5.7)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.37.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.13)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.30)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.99)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain) (3.0.0)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.1)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.13)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.30)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.99)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.3.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain-community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.2.12-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.12 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting openai\n",
            "  Downloading openai-1.40.6-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Downloading openai-1.40.6-py3-none-any.whl (361 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m361.3/361.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jiter, openai\n",
            "Successfully installed jiter-0.5.0 openai-1.40.6\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.21-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.29 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.2.30)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.40.6)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (0.1.99)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.29->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.29->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.29->langchain-openai) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.29->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.29->langchain-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
            "Downloading langchain_openai-0.1.21-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.8/49.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.1.21 tiktoken-0.7.0\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade gradio\n",
        "%pip install langchain\n",
        "%pip install langchain-community\n",
        "%pip install openai\n",
        "%pip install -U langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvNgNcUfR4y2"
      },
      "source": [
        "## The most basic Chatbot possible:\n",
        "\n",
        "This simply uses a user interface attached to a LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DiWaBwnwR4y2",
        "outputId": "2fc42f9c-b2f9-43e4-c626-bc426f756a92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://2724d60175b596b0c6.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://2724d60175b596b0c6.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import gradio as gr\n",
        "\n",
        "llm = ChatOpenAI(temperature=1.0, model='gpt-3.5-turbo-16k')\n",
        "\n",
        "def predict(message, history):\n",
        "    gpt_response = llm.invoke(message)\n",
        "    return gpt_response.content\n",
        "\n",
        "gr.ChatInterface(predict).launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DrI1H3UzR4y2"
      },
      "source": [
        "## Retrieval Augmented Generation Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mt7FKeMGR4y2"
      },
      "source": [
        "### Source and clean data for RAG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ugz2-GMMR4y2"
      },
      "outputs": [],
      "source": [
        "# %pip install bs4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DftYjmvTR4y2"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "def scrape_website_text(url):\n",
        "    # Send a GET request to the Wikipedia page\n",
        "    response = requests.get(url)\n",
        "\n",
        "    # Check if the request was successful\n",
        "    if response.status_code == 200:\n",
        "        # Parse the HTML content of the page\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract all the text from paragraphs and other relevant tags\n",
        "        paragraphs = soup.find_all(['p', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6'])\n",
        "        text = ' '.join([para.get_text() for para in paragraphs])\n",
        "\n",
        "        # Clean the text by removing special characters\n",
        "        cleaned_text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "\n",
        "        return cleaned_text.strip()\n",
        "    else:\n",
        "        return \"Failed to retrieve the page\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "l1hzmwuXR4y2"
      },
      "outputs": [],
      "source": [
        "url = \"\"\"https://www.cbsnews.com/news/paris-olympics-2024-200-meters-noah-lyles-kenny-bednarek-letsile-tebogo/\"\"\"  # put any website page in here\n",
        "cleaned_text = scrape_website_text(url)\n",
        "\n",
        "# you can test that this has worked using the line below (uncomment to use)\n",
        "# print(cleaned_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if0wV-n0R4y2"
      },
      "source": [
        "### Split and chunk the text for embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WljuuBRSR4y3"
      },
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    # Set a really small chunk size, just to show.\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mFFYhyyyR4y4",
        "outputId": "30fdb400-4acd-4ca7-fb86-f429997a6e68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "page_content='Watch CBS News Noah Lyles of Team USA wins bronze in 200 meters after testing positive for COVID Botswanas Letsile Tebogo claims gold \n",
            "    By\n",
            "                        \n",
            "                      Allison Elyse Gualtieri\n",
            " \n",
            "Updated on  August 8 2024  819 PM EDT\n",
            "           CBS News'\n",
            "page_content='Noah Lyles sought to follow up his gold medal in the 100 meters with a matching one in the 200 meters On Thursday the favorite instead claimed the bronze in the 2024 Paris Olympics  and revealed that he had been diagnosed with COVID19 two days earlier  He finished behind Letsile Tebogo of Botswana who won gold and fellow American Kenny Bednarek who garnered the silver  Lyles a 27yearold from northern Virginia said in an interview with NBC after the race that he woke up early Tuesday feeling really horrible  I knew it was more than just being sore from the 100 he said Woke up the doctors and we tested and unfortunately it came up that I was positive for COVID  Lyles was seen almost immediately after the race asking for water and going down to one knee He sat on the side of the track for an extended period of time as medical personnel attended to him Photographs and video from after the event showed him being taken off the track in a wheelchair  He said in the interview Its'\n"
          ]
        }
      ],
      "source": [
        "texts = text_splitter.create_documents([cleaned_text])\n",
        "print(texts[0])\n",
        "print(texts[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOdncuzqR4y4"
      },
      "source": [
        "### Embed the documents and save in a Vector database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1Jg9VIeiR4y4",
        "outputId": "6f854fd6-d467-4222-c587-69d67c67c126",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Downloading faiss_cpu-1.8.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.8.0.post1\n"
          ]
        }
      ],
      "source": [
        "%pip install faiss-cpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WOzCZUuR4y4"
      },
      "source": [
        "The Cell below does cost money to run, however the embeddings don't have to be done every time. Once a vector database is made, it can be saved and retrieved for later use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CS9of2RIR4y4"
      },
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "\n",
        "vector_database = FAISS.from_documents(texts, embedding_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFPR3TeuR4y4"
      },
      "source": [
        "Below is a test to see if we can retrieve some relevant context chunks from our document store:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "PmeEMNxwR4y4",
        "outputId": "6bdb9431-36e3-45da-e384-66df83b099a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Document(page_content='by a mere five thousandths of a second American Fred Kerley rounded out the medals in photo finish with the top four finishers separated by just 04 seconds and the top seven just 09  a literal blink of an eye Bednarek claimed the silver in the 200 meters in Tokyo but fell behind in the 100 meters in Paris finishing seventh at the Stade de France Lyles also took home the bronze in the 200 meters in Tokyo He added the 100meter sprint for the Paris Games which paid off earlier this week The 2024 Summer Games have been good for Team USA which led the medal count in athletics  the track and field events  going into competition Friday six gold seven silver and six bronze\\xa0 2024 Summer Olympics in Paris Allison Elyse Gualtieri is a Senior News Editor for CBSNewscom working on a wide variety of subjects including crime longerform features and feelgood news She previously worked for the Washington Examiner and US News and World Report among other outlets'), Document(page_content='Noah Lyles sought to follow up his gold medal in the 100 meters with a matching one in the 200 meters On Thursday the favorite instead claimed the bronze in the\\xa02024 Paris Olympics\\xa0 and revealed that he had been diagnosed with COVID19 two days earlier\\xa0 He finished behind Letsile Tebogo of Botswana who won gold and fellow American Kenny Bednarek who garnered the silver\\xa0 Lyles a 27yearold from northern Virginia said in an interview with NBC after the race that he woke up early Tuesday feeling really horrible  I knew it was more than just being sore from the 100 he said Woke up the doctors and we tested and unfortunately it came up that I was positive for COVID\\xa0 Lyles was seen almost immediately after the race asking for water and going down to one knee He sat on the side of the track for an extended period of time as medical personnel attended to him Photographs and video from after the event showed him being taken off the track in a wheelchair\\xa0 He said in the interview Its'), Document(page_content='one more race the 4x100meters relay but he told NBC after the 200 meters he wasnt sure if he would compete in that event Im feeling more on the side of letting Team USA do their thing Theyve proven with great certainty they can handle it without me he said If thats the case coming off today Im perfectly fine saying Hey you guys do your thing You have more than enough speed to handle it and get the gold medal \\xa0 Later on Thursday Lyles appeared to say in an Instagram post that he would not compete in that event writing I believe this will be the end of my 2024 Olympics It is not the Olympic I dreamed of but it has left me with so much Joy in my heart Lyles wrote I hope everyone enjoyed the show Whether you were rooting for me or against me you have to admit you watched didnt you See you next time On Sunday Lyles narrowly edged Kishane Thompson to capture the 100meter gold besting the Jamaican by a mere five thousandths of a second American Fred Kerley rounded out the medals in photo')]\n"
          ]
        }
      ],
      "source": [
        "query = \"Who won gold in the men's 200m sprint at the 2024 Paris Olympics?\"\n",
        "\n",
        "print(vector_database.similarity_search(query, 3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpUIpjaDR4y4"
      },
      "source": [
        "### Include the RAG pipeline into our chatbot prototype:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8VoCnsSuR4y4",
        "outputId": "f3ed94d2-41e9-457a-87b5-5299420ff1d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://37d575e90377491040.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://37d575e90377491040.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "import gradio as gr\n",
        "\n",
        "llm = ChatOpenAI(temperature=1.0, model='gpt-3.5-turbo-16k')\n",
        "\n",
        "def predict(message, history):\n",
        "    context = vector_database.similarity_search(message, 3)\n",
        "    formatted_prompt = f\"\"\"{context} \\nUse the above context to answer the follwing question: \\n{message}\"\"\"\n",
        "    gpt_response = llm.invoke(formatted_prompt)\n",
        "    return gpt_response.content\n",
        "\n",
        "gr.ChatInterface(predict).launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5XplEwtR4y5"
      },
      "source": [
        "## RAG Chatbot with Conversational History"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ULQXIsX9R4y5",
        "outputId": "e2654941-dee9-4c78-a695-e38d3da424e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ec889ea76830a462cd.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ec889ea76830a462cd.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "import gradio as gr\n",
        "\n",
        "llm = ChatOpenAI(temperature=1.0, model='gpt-3.5-turbo-16k')\n",
        "\n",
        "def predict(message, history):\n",
        "    history_langchain_format = []\n",
        "    for human, ai in history:\n",
        "        history_langchain_format.append(HumanMessage(content=human))\n",
        "        history_langchain_format.append(AIMessage(content=ai))\n",
        "    history_langchain_format.append(HumanMessage(content=message))\n",
        "    context = vector_database.similarity_search(message, 3)\n",
        "    formatted_prompt = f\"\"\"{context} \\nUse the above context to answer the follwing question: \\nHere is your conversation history with the user and their latest question: {history_langchain_format}\"\"\"\n",
        "    print(history_langchain_format)\n",
        "    print(context)\n",
        "    gpt_response = llm.invoke(formatted_prompt)\n",
        "    return gpt_response.content\n",
        "\n",
        "gr.ChatInterface(predict).launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp-Ns98fR4y5"
      },
      "source": [
        "## Conversational Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyxOlY_rR4y5"
      },
      "source": [
        "### import the libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Ef5EgC1tR4y5"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import Tool\n",
        "from langchain.tools import tool\n",
        "from langchain.globals import set_debug\n",
        "set_debug(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "8RfzcAMkR4y5",
        "outputId": "2e5afd52-e240-4622-cba3-eb92bd434743",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading wikipedia-1.4.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2024.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.5)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-py3-none-any.whl size=11679 sha256=eee7759ea69c2e21587f203aabfd5798d3a7dde379978989ac19e42a89543876\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/b6/c5/93f3dec388ae76edc830cb42901bb0232504dfc0df02fc50de\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ]
        }
      ],
      "source": [
        "%pip install wikipedia\n",
        "# %pip install langchainhub"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObAQhg9CR4y5"
      },
      "source": [
        "### Define the tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "2jNssXfBR4y5"
      },
      "outputs": [],
      "source": [
        "# defining the tool for the context retrieval function\n",
        "@tool\n",
        "def context_retreival(query: str) -> str:\n",
        "    \"\"\"This tool returns relevant context documents about the 200m sprint at the 2024 olympics in Paris. Ask this tool any question about the 2024 200m sprint finals and who won it.\"\"\"\n",
        "\n",
        "    context = vector_database.similarity_search(query, 3)\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "tsNSGIZ5R4y5"
      },
      "outputs": [],
      "source": [
        "from langchain_community.tools import WikipediaQueryRun\n",
        "from langchain_community.utilities import WikipediaAPIWrapper\n",
        "\n",
        "# defining the tool for the wiki retrieval function\n",
        "@tool\n",
        "def wiki_lookup(query: str) -> str:\n",
        "    \"\"\"This tool should be used for questions about particular people and their achievements. It returns a context document from wikipedia.\"\"\"\n",
        "\n",
        "    wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
        "\n",
        "    context = wikipedia.run(query)\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "19LtwK_aR4y5"
      },
      "outputs": [],
      "source": [
        "tools = [\n",
        "    context_retreival,\n",
        "    wiki_lookup\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxgHGtE_R4y5"
      },
      "source": [
        "### Initialise the prompt and agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XmXkEkqqR4y5"
      },
      "outputs": [],
      "source": [
        "# from langchain import hub\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "# The commented out lines below did not work in colab, so I have manually recreated the prompt in the lines below those\n",
        "# Get the prompt to use - you can modify this!\n",
        "# prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "assistant_system_message = \"\"\"You are a helpful assistant. \\\n",
        "Use tools (only if necessary) to best answer the users questions.\"\"\"\n",
        "prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"system\", assistant_system_message),\n",
        "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
        "        (\"user\", \"{input}\"),\n",
        "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "IOAIVMkqR4y5"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import create_tool_calling_agent\n",
        "agent = create_tool_calling_agent(llm, tools, prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LVHsLEG9R4y5"
      },
      "outputs": [],
      "source": [
        "from langchain.agents import AgentExecutor\n",
        "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL_pBBcVR4y5"
      },
      "source": [
        "### Launch a user interface for experimentation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xba0HDuyR4y5",
        "outputId": "4a85a622-7701-477f-ca5b-f0ebc369dfed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://6cd8430b98b8d47a3d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6cd8430b98b8d47a3d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [6ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"agent_scratchpad\": []\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [13ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [2ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant. Use tools (only if necessary) to best answer the users questions.\\nHuman: search wikipedia for solar flares\\nHuman: search wikipedia for solar flares\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [782ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"tool_calls\",\n",
            "          \"model_name\": \"gpt-3.5-turbo-16k-0613\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"\",\n",
            "            \"additional_kwargs\": {\n",
            "              \"tool_calls\": [\n",
            "                {\n",
            "                  \"index\": 0,\n",
            "                  \"id\": \"call_NfpwVQ5UM6ARpBXLk48jQibQ\",\n",
            "                  \"function\": {\n",
            "                    \"arguments\": \"{\\n\\\"query\\\": \\\"solar flares\\\"\\n}\",\n",
            "                    \"name\": \"wiki_lookup\"\n",
            "                  },\n",
            "                  \"type\": \"function\"\n",
            "                }\n",
            "              ]\n",
            "            },\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"tool_calls\",\n",
            "              \"model_name\": \"gpt-3.5-turbo-16k-0613\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-0c3ff6e4-e00a-4994-a8f4-02994d29fecb\",\n",
            "            \"tool_calls\": [\n",
            "              {\n",
            "                \"name\": \"wiki_lookup\",\n",
            "                \"args\": {\n",
            "                  \"query\": \"solar flares\"\n",
            "                },\n",
            "                \"id\": \"call_NfpwVQ5UM6ARpBXLk48jQibQ\",\n",
            "                \"type\": \"tool_call\"\n",
            "              }\n",
            "            ],\n",
            "            \"tool_call_chunks\": [\n",
            "              {\n",
            "                \"name\": \"wiki_lookup\",\n",
            "                \"args\": \"{\\n\\\"query\\\": \\\"solar flares\\\"\\n}\",\n",
            "                \"id\": \"call_NfpwVQ5UM6ARpBXLk48jQibQ\",\n",
            "                \"index\": 0,\n",
            "                \"type\": \"tool_call_chunk\"\n",
            "              }\n",
            "            ],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [815ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:wiki_lookup] Entering Tool run with input:\n",
            "\u001b[0m\"{'query': 'solar flares'}\"\n",
            "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[tool:wikipedia] Entering Tool run with input:\n",
            "\u001b[0m\"solar flares\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[tool:wikipedia] [1.53s] Exiting Tool run with output:\n",
            "\u001b[0m\"Page: Solar flare\n",
            "Summary: A solar flare is a relatively intense, localized emission of electromagnetic radiation in the Sun's atmosphere. Flares occur in active regions and are often, but not always, accompanied by coronal mass ejections, solar particle events, and other eruptive solar phenomena. The occurrence of solar flares varies with the 11-year solar cycle.\n",
            "Solar flares are thought to occur when stored magnetic energy in the Sun's atmosphere accelerates charged particles in the surrounding plasma. This results in the emission of electromagnetic radiation across the electromagnetic spectrum.\n",
            "The extreme ultraviolet and X-ray radiation from solar flares is absorbed by the daylight side of Earth's upper atmosphere, in particular the ionosphere, and does not reach the surface. This absorption can temporarily increase the ionization of the ionosphere which may interfere with short-wave radio communication. The prediction of solar flares is an active area of research.\n",
            "Flares also occur on other stars, where the term stellar flare applies.\n",
            "\n",
            "\n",
            "\n",
            "Page: May 2024 solar storms\n",
            "Summary: The solar storms of May 2024 were a series of powerful solar storms with extreme solar flares and geomagnetic storm components that occurred from 10–13 May 2024 during solar cycle 25. The geomagnetic storm was the most powerful to affect Earth since March 1989, and produced aurorae at far more equatorial latitudes than usual in both the Northern and Southern Hemispheres.\n",
            "\n",
            "\n",
            "\n",
            "Page: List of solar storms\n",
            "Summary: Solar storms of different types are caused by disturbances on the Sun, most often from coronal mass ejections (CMEs) and solar flares from active regions, or, less often, from coronal holes. Minor to active solar storms (i.e. storming restricted to higher latitudes) may occur under elevated background solar wind conditions when the interplanetary magnetic field (IMF) orientation is southward, toward the Earth (which also leads to much stronger storming conditions from CME-related sources).\"\n",
            "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[chain:AgentExecutor > tool:wiki_lookup] [1.53s] Exiting Tool run with output:\n",
            "\u001b[0m\"Page: Solar flare\n",
            "Summary: A solar flare is a relatively intense, localized emission of electromagnetic radiation in the Sun's atmosphere. Flares occur in active regions and are often, but not always, accompanied by coronal mass ejections, solar particle events, and other eruptive solar phenomena. The occurrence of solar flares varies with the 11-year solar cycle.\n",
            "Solar flares are thought to occur when stored magnetic energy in the Sun's atmosphere accelerates charged particles in the surrounding plasma. This results in the emission of electromagnetic radiation across the electromagnetic spectrum.\n",
            "The extreme ultraviolet and X-ray radiation from solar flares is absorbed by the daylight side of Earth's upper atmosphere, in particular the ionosphere, and does not reach the surface. This absorption can temporarily increase the ionization of the ionosphere which may interfere with short-wave radio communication. The prediction of solar flares is an active area of research.\n",
            "Flares also occur on other stars, where the term stellar flare applies.\n",
            "\n",
            "\n",
            "\n",
            "Page: May 2024 solar storms\n",
            "Summary: The solar storms of May 2024 were a series of powerful solar storms with extreme solar flares and geomagnetic storm components that occurred from 10–13 May 2024 during solar cycle 25. The geomagnetic storm was the most powerful to affect Earth since March 1989, and produced aurorae at far more equatorial latitudes than usual in both the Northern and Southern Hemispheres.\n",
            "\n",
            "\n",
            "\n",
            "Page: List of solar storms\n",
            "Summary: Solar storms of different types are caused by disturbances on the Sun, most often from coronal mass ejections (CMEs) and solar flares from active regions, or, less often, from coronal holes. Minor to active solar storms (i.e. storming restricted to higher latitudes) may occur under elevated background solar wind conditions when the interplanetary magnetic field (IMF) orientation is southward, toward the Earth (which also leads to much stronger storming conditions from CME-related sources).\"\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"input\": \"\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad> > chain:RunnableLambda] [2ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad> > chain:RunnableParallel<agent_scratchpad>] [5ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > chain:RunnableAssign<agent_scratchpad>] [10ms] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"System: You are a helpful assistant. Use tools (only if necessary) to best answer the users questions.\\nHuman: search wikipedia for solar flares\\nHuman: search wikipedia for solar flares\\nAI: \\nTool: Page: Solar flare\\nSummary: A solar flare is a relatively intense, localized emission of electromagnetic radiation in the Sun's atmosphere. Flares occur in active regions and are often, but not always, accompanied by coronal mass ejections, solar particle events, and other eruptive solar phenomena. The occurrence of solar flares varies with the 11-year solar cycle.\\nSolar flares are thought to occur when stored magnetic energy in the Sun's atmosphere accelerates charged particles in the surrounding plasma. This results in the emission of electromagnetic radiation across the electromagnetic spectrum.\\nThe extreme ultraviolet and X-ray radiation from solar flares is absorbed by the daylight side of Earth's upper atmosphere, in particular the ionosphere, and does not reach the surface. This absorption can temporarily increase the ionization of the ionosphere which may interfere with short-wave radio communication. The prediction of solar flares is an active area of research.\\nFlares also occur on other stars, where the term stellar flare applies.\\n\\n\\n\\nPage: May 2024 solar storms\\nSummary: The solar storms of May 2024 were a series of powerful solar storms with extreme solar flares and geomagnetic storm components that occurred from 10–13 May 2024 during solar cycle 25. The geomagnetic storm was the most powerful to affect Earth since March 1989, and produced aurorae at far more equatorial latitudes than usual in both the Northern and Southern Hemispheres.\\n\\n\\n\\nPage: List of solar storms\\nSummary: Solar storms of different types are caused by disturbances on the Sun, most often from coronal mass ejections (CMEs) and solar flares from active regions, or, less often, from coronal holes. Minor to active solar storms (i.e. storming restricted to higher latitudes) may occur under elevated background solar wind conditions when the interplanetary magnetic field (IMF) orientation is southward, toward the Earth (which also leads to much stronger storming conditions from CME-related sources).\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > llm:ChatOpenAI] [3.04s] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \"Here is some information about solar flares from Wikipedia:\\n\\n1. Solar flare: A solar flare is a relatively intense, localized emission of electromagnetic radiation in the Sun's atmosphere. Flares occur in active regions and are often accompanied by coronal mass ejections, solar particle events, and other eruptive solar phenomena. The occurrence of solar flares varies with the 11-year solar cycle.\\n[source](https://en.wikipedia.org/wiki/Solar_flare)\\n\\n2. May 2024 solar storms: The solar storms that occurred in May 2024 were a series of powerful solar storms with extreme solar flares and geomagnetic storm components. These storms produced aurorae at far more equatorial latitudes than usual in both the Northern and Southern Hemispheres.\\n[source](https://en.wikipedia.org/wiki/May_2024_solar_storms)\\n\\n3. List of solar storms: This page provides information about different types of solar storms caused by disturbances on the Sun, mainly coronal mass ejections (CMEs) and solar flares from active regions. It also mentions that minor to active solar storms can occur under elevated background solar wind conditions.\\n[source](https://en.wikipedia.org/wiki/List_of_solar_storms)\\n\\nLet me know if there is anything else I can assist you with!\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"model_name\": \"gpt-3.5-turbo-16k-0613\"\n",
            "        },\n",
            "        \"type\": \"ChatGenerationChunk\",\n",
            "        \"message\": {\n",
            "          \"lc\": 1,\n",
            "          \"type\": \"constructor\",\n",
            "          \"id\": [\n",
            "            \"langchain\",\n",
            "            \"schema\",\n",
            "            \"messages\",\n",
            "            \"AIMessageChunk\"\n",
            "          ],\n",
            "          \"kwargs\": {\n",
            "            \"content\": \"Here is some information about solar flares from Wikipedia:\\n\\n1. Solar flare: A solar flare is a relatively intense, localized emission of electromagnetic radiation in the Sun's atmosphere. Flares occur in active regions and are often accompanied by coronal mass ejections, solar particle events, and other eruptive solar phenomena. The occurrence of solar flares varies with the 11-year solar cycle.\\n[source](https://en.wikipedia.org/wiki/Solar_flare)\\n\\n2. May 2024 solar storms: The solar storms that occurred in May 2024 were a series of powerful solar storms with extreme solar flares and geomagnetic storm components. These storms produced aurorae at far more equatorial latitudes than usual in both the Northern and Southern Hemispheres.\\n[source](https://en.wikipedia.org/wiki/May_2024_solar_storms)\\n\\n3. List of solar storms: This page provides information about different types of solar storms caused by disturbances on the Sun, mainly coronal mass ejections (CMEs) and solar flares from active regions. It also mentions that minor to active solar storms can occur under elevated background solar wind conditions.\\n[source](https://en.wikipedia.org/wiki/List_of_solar_storms)\\n\\nLet me know if there is anything else I can assist you with!\",\n",
            "            \"response_metadata\": {\n",
            "              \"finish_reason\": \"stop\",\n",
            "              \"model_name\": \"gpt-3.5-turbo-16k-0613\"\n",
            "            },\n",
            "            \"type\": \"AIMessageChunk\",\n",
            "            \"id\": \"run-b9f23f83-6181-4f7b-a585-c081b20792ee\",\n",
            "            \"tool_calls\": [],\n",
            "            \"invalid_tool_calls\": []\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": null,\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] Entering Parser run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence > parser:ToolsAgentOutputParser] [1ms] Exiting Parser run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor > chain:RunnableSequence] [3.07s] Exiting Chain run with output:\n",
            "\u001b[0m[outputs]\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[chain:AgentExecutor] [5.44s] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output\": \"Here is some information about solar flares from Wikipedia:\\n\\n1. Solar flare: A solar flare is a relatively intense, localized emission of electromagnetic radiation in the Sun's atmosphere. Flares occur in active regions and are often accompanied by coronal mass ejections, solar particle events, and other eruptive solar phenomena. The occurrence of solar flares varies with the 11-year solar cycle.\\n[source](https://en.wikipedia.org/wiki/Solar_flare)\\n\\n2. May 2024 solar storms: The solar storms that occurred in May 2024 were a series of powerful solar storms with extreme solar flares and geomagnetic storm components. These storms produced aurorae at far more equatorial latitudes than usual in both the Northern and Southern Hemispheres.\\n[source](https://en.wikipedia.org/wiki/May_2024_solar_storms)\\n\\n3. List of solar storms: This page provides information about different types of solar storms caused by disturbances on the Sun, mainly coronal mass ejections (CMEs) and solar flares from active regions. It also mentions that minor to active solar storms can occur under elevated background solar wind conditions.\\n[source](https://en.wikipedia.org/wiki/List_of_solar_storms)\\n\\nLet me know if there is anything else I can assist you with!\"\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.schema import AIMessage, HumanMessage\n",
        "import gradio as gr\n",
        "\n",
        "llm = ChatOpenAI(temperature=1.0, model='gpt-3.5-turbo-16k')\n",
        "\n",
        "def predict(message, history):\n",
        "    history_langchain_format = []\n",
        "    for human, ai in history:\n",
        "        history_langchain_format.append(HumanMessage(content=human))\n",
        "        history_langchain_format.append(AIMessage(content=ai))\n",
        "    history_langchain_format.append(HumanMessage(content=message))\n",
        "\n",
        "    gpt_response = agent_executor.invoke({\"input\": message, \"chat_history\": history_langchain_format})\n",
        "    return gpt_response['output']\n",
        "\n",
        "\n",
        "gr.ChatInterface(predict).launch(debug=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}